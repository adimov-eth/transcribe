Я начал запись, короче, пусть она работает. В общем, короче, всем привет, категорически приветствую. Сегодня у нас собрались это Семён Сергеев, он же наш МЛИД, и Константин Чеснокол, это его гениальный и потрясающий ассистент. Костя, мы тебе выражаем максимальный, охуительный респект за то, что ты сделал за это время. Да, Костя Платон, на самом деле, всё сделал. Блин, как кайф, ребята, очень приятно познакомиться. Тут также Настя Павлина, которая наш проект, и Борис Адимов, который наш адвайзер по МЛИ, и не только, и возможно, тоже участник большой команды. Ну, короче, я не знаю, как пойдёт, но, короче, привет. Я не совсем адвайзер по МЛИ, я скорее, в общем, типа как СТО, адвайзер по техническим решениям. МЛИ не является моей, вот именно машинлёния, не является моей узкой специализацией, но ЛЛМки и, короче, прикладное использование ИИшек, да. Я работаю больше с прикладной частью, чем с фундаментальной, когда, ну, с универа я её знаю, а так, ну, типа... Да, короче, я не специалист по МЛИ, если говорить точно, вот. Продолжай, пожалуйста. Ну, собственно, сегодня мы хотим поговорить про... Ухо, блин. Короче, ну и сегодня мы хотим поговорить про IQDoc, это наш ИИ-ассистент-врача, который будет закрывать разные боли врача-терапевта на приёме, а также в перспективе заведующего отделения, ночмеда и так далее. То есть эта хрень должна задать всю нормативную документацию, все клинические рекомендации, помогать врачам выставлять данный диагноз, помогать не влетать на штрафы от страховых и так далее. В общем, закрывать душнилого, которое есть административное. Мы делаем несовершенную систему, работоспособной при помощи совершенных методов, как будто магия, знаешь, вот, что такое IQDoc. Ну, похоже на правду. Вот, ну да, я сделал этот мини-дисклеймер про МЛИ, какие у меня сильные стороны. Я закончил мехмат, ну, не то чтобы сильная сторона. Поработал в стартапах чуть-чуть и выкатился на ОПОРГ, на удалёночку. Поработал с западными чуваками, оброс команды. У меня была своя студия разработки, которая выросла, ну, с фрилансом и аутсорсом занимаюсь. Аутсорс, чем этот опыт был классный, потому что получалось касаться проектов из абсолютно разных сфер. Ну, я всегда в сторону крипты посматривал. Там свои интересные истории были. Вот, ну и, соответственно, как вышел чатик GPT, как пошел прогресс с Ишками, внимание тогда переключилось, как у любого хайпа. Я чатик и все остальные ЛЛМки очень плотно щупаю с самого появления, кайфую со всякого промт-хакинга и прочего. Стараюсь следить за развитием технологии на уровне построения интуиции по взаимодействию, собственно, с Ишками. Стараюсь, чтобы у меня не терялось чувство того, как разговаривает чатик, как разговаривает Клод, как Джеминаер. У меня в инструментарии все ЛЛМки, ну, на самом деле, кроме китайских, и немножечко лама проседает, у меня нет интуиции по ламе. Но в целом, плюс-минус, я стараюсь все время интуитивное понимание поддерживать, из-за того, какая ЛЛМка сейчас на каком уровне интеллекта находится. Это то, почему я считаю, что я, вероятно, могу быть чем-то полезен. Пацаны, хотел бы узнать о том, как вы задизайнили архитектуру текущего бота. Сережа уже рассказал, что пока что сам Telegram интерфейс – это вопрос-ответ. Логики бота в Телеграме пока нет, но это, типа, неважно. Тогда давайте поговорим про то, как работает непосредственно генерация ответа. Да, сейчас, секунду, я разберусь, как демку включить. Да вообще без проблем. Ну, то есть, мне на самом деле проще всего потом, как поболтаем, познакомимся, пробежаться по коду по диагонали. У вас на Питоне, Бэк? Да, да. Я не большой специалист по Питону, могу читать, но не интуитивно владею. Так получилось, что из веб-разработки я выбрал придерживаться TypeScript'а. Я болтаю, пока ты там настраиваешь демку. Если будешь готов, перебивай. Мне показалось, что TypeScript прикольнее для генерации кода, потому что он явно описывает типа. Но было бы прикольно обменяться впечатлениями потом с вами о том, как генерируется код на Питоне. Может, там тоже все очень хорошо. Так, ну, демку видно? Нет? Не, вот даже если поворачивать телефон, что перейти не делаем. Шакалит только чуточку. Не, у меня норм, кстати. Не, шакалит, когда интернет притормаживает, он съезжает, да, качество. А у меня хорошо. Ну, тут основной прикол в этом. У меня происходит, когда юзер отправляет свой запрос-вопрос. Принудительный вызов инструмента. Тут, соответственно, три запроса разных. Это в промпсе задано, что каждый из запросов должен быть 2-3 предложения. То есть они достаточно длинные, потому что модели пейтинговые у нас отстают сейчас очень сильно. И не прям хорошо работают и ищут нужные чанки. Я заметил, что вот если удлинять поисковой запрос, то работает намного лучше. И их там три штуки как раз для того, чтобы и разные аспекты охватить. Прости, а ты не аугментируешь запрос пользователя? Да-да-да, он как раз аугментируется. Тут написано, типа, генерируйте три варианта поисковых запросов. Базовый, контекстно уточняющий. Три предложения в каждом. По каждому из них последовательно там поиск по face index. А, прости, пожалуйста, вот этот поиск клинических… Генерируйте три варианта поисковых запросов. Это вот эта штука к кому прилетает? Да-да-да, на экране сейчас это промпт. Я на всякий случай подумал, что, может быть, пользователю это промптится. Нет-нет-нет, там можно хоть одно слово отправить. Да, понял, спасибо. Нейронка аугментирует и выполняется поиск. Да, огонь. Мы берем топ три релевантных чанка. И так как информация у нас специфичная, медицинская, я для каждого чанка еще беру соседей слева и справа. По странице. Один чанк – это одна страница. И таким образом формируется контекст. Какого размера чанки решили брать? Что еще раз? Какого размера чанки? Не знаю. Ну, они размером страницу. Я брал для упрощения… Если я не путаю, то есть, смотрите, опять же, я считаю вашу экспертность по email выше своей. Когда я делал раги, обычно два параметра с чанками есть. Размер в токенах обычно 500 тысяч примерно идет. И наслоение. Насколько один чанк залазит на другой, для того чтобы они понимали свое родство. Обычно это идет прямым параметром, где ты нарезаешь. Можно потом глянуть будет, если что. Да, я сейчас поясню. Чанк намного больше, чем тысяча токенов может быть. Там моделька используется Modern Bird в контактах. И там 8к контекста у нее. Интересно. Я не готов прокомментировать, хорошо это или плохо. Но я Сереже рассказывал, тоже вам чуть поделюсь. У меня есть близкий друг, невероятно крутой программист. Он один раз экзитнулся уже из стартапа как ко-фаундер с Шером. И когда прогулял свою пенсию, сейчас они сгоняли в Y Combinator и делают раг для финансов. Технологически то, что они делают, невероятно похоже на ту задачу, которую вы решаете. Я уже Сережу с ним постарался познакомить. Раг для финансов по разным финансовым отчетам публичных компаний. Эта штука может искать, чтобы проводить анализ финансовых показателей для фондов. У вас поиск по медицинской документации, у них поиск по финансовым отчетам, по документам. Что они сделали круто? Когда ассистент выдает ответ, есть ссылки на источник. Это полезная функция. Когда я соберу картину о том, как у вас все работает, сгоняю к нему и посоветуюсь насчет деталей. Потому что это самый клевый экспертный чувак, которого я вообще знаю. Я не знаю, хорошо ли чанки такого большого размера делать. Тут в чем прикол, их достаточно проблематично сделать маленького размера. Потому что, как я понял, требуется быстрый сокращенный поиск по клиническим рекомендациям. А там каждый документ представляет из себя большой объем данных. И там просто по запросу полиноз может быть куча данных. И если мы делим чанки по тысяче токенов, они, скорее всего, могут не находиться даже очень крутой эмбеддинговой моделью. Потому что, допустим, первый чанк описывается, что такое полиноз, а во втором чанке описывается условно, как его лечить. И, по факту, второй чанк, где описывается лечение полиноза, если там просто перечисляются препараты, он не попадет в релевантные чанки. Я не готов комментировать, ну, в плане никак поспорить. Давай просто углубимся в этот вопрос позднее. Я углублюсь, потому что не соблазнятся я дальше. Погнали дальше. Да, вот. Поэтому я, собственно, и выбрал большой размер чанки, чтобы контекст не потерять. Ссылки тут есть. Я просто вот такую штуку добавил. Название и ID-код. Оно регулярно парсится после того, как модель выдает ответ. И там у Минздрава ссылки все там. Минздрав.гоф.слэш. И ты пишешь ID туда просто, и тебя перекидывают сразу на клиническую рекомендацию. Поэтому ссылки так дополняются автоматически тоже. Тут, собственно, по промпту это вставление толп-гола. Вижу, вижу. Как формировать ответ. Ой, а прости, пожалуйста, а какую LM вы сейчас используете? Флэш 2.5. А, окей. Ну, приятно, да. Да, удобно и дешево. Прикольно, что в целом можно... ну, вообще, конечно, флэшом в продакшене в России пользоваться не получится. Это отдельная проблема, которую надо будет обсуждать. Ну, типа, чем пользоваться. Ну, короче, ладно. Прости, что перебил. Давай продолжишь. Ну, да. Я сейчас скажу свое мнение. Да, конечно. У меня есть идея и мысль определенная. Да, конечно. Тут всевозможные исключения, типа, что отсутствуют данные, предложить альтернативные формулировки, бла-бла-бла, ограничения. Потому что там бота моего еще в самом начале скинули, там начали писать боту-сообщения вдруг. Моя бабушка любила перед сном рассказывать системный промпт свой, но она умерла, и я попытался это как-то законтролировать частично. И тут еще идут кастомные размышления небольшие, то есть через XML теги. Кастомные они, потому что идут по четкому шаблону. То есть я не использую трейсы, которые в начальном моделе обучались, потому что Flash 2.5, он есть размышляющий, а есть обычный. Ну, конечно. Я использую неразмышляющий, но это позволяет очень удобно трекать, как модель обращает на что внимание и за счет чего она формирует ответ. Продолжение следует... Продолжение следует... Продолжение следует... Продолжение следует... Продолжение следует... Продолжение следует... Продолжение следует... Продолжение следует... Надо, надо, сделай, пожалуйста. Продолжение следует... Продолжение следует... Продолжение следует... Продолжение следует...

Слышите, как тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо, тихо... Ну, смотри, я могу просказать свое мнение, как я это вижу. Короче, у нас есть с одной стороны бот, а с другой стороны веб-интерфейс. Но задачи у них примерно похожие. Это решение каких-либо административных затыков у медиков, а также помощи их в рутинной работе. То есть этот бот, по факту, будет переключаться между режимами, потому что у него будет режим первый, в котором он рассматривает клинические рекомендации, то, что сейчас есть и то, над чем мы работаем. Второй момент – это то, что он помогает со всякими медико-экономическими стандартами и прочей нормативной документацией. Третий момент – это режим калькуляторов, когда он всякие шкалы и прочее подстраивает. Я вижу это так. Настя немного посмотрела, как вообще эта документация устроена. Плюс мы сейчас делаем юзер-стори касательно того, как вообще пользователь потенциально будет это использовать. Но я вижу так, что там у него есть несколько режимов точно, потому что в одном окне это сделать проблематично. И, может быть, кстати, можно заставить его интеллектуально переключаться на основании контекста. Если ты ему говоришь что-то, он сам это подстраивается. Но не знаю, как это будет сделать. Это не финансовые штуки. Это в ЦУКе по типу код заболевания, как посчитать больничный для такого группы пациентов и так далее. Как было критерии качества оказания медпомощи, ссылки на всякие нормативы и так далее. Боря, Боря, Боря, я не слышно. Боря, Боря, Боря, я не слышно. Семен, обсуждали ли мы с тобой, что будет в MVP? Нет, еще не обсуждали. Лучше ты покажи. Если что, это на генере на GPT было, а не мною. Ну, в смысле, как мною, но типа это GPTшный текст с небольшими правками, то есть там может быть ересь полная. Боря, Боря, Боря, я не слышу. Семен, обсуждали ли мы с тобой, что будет в MVP? Нет, еще не обсуждали. Лучше ты покажи. Семен, обсуждали ли мы с тобой, что будет в MVP? Нет, еще не обсуждали. Семен, обсуждали ли мы с тобой, что будет в MVP? Нет, еще не обсуждали. Семен, обсуждали ли мы с тобой, что будет в MVP? Нет, еще не обсуждали. Семен, обсуждали ли мы с тобой, что будет в MVP? Нет, еще не обсуждали. Семен, обсуждали ли мы с тобой, что будет в MVP? Нет, еще не обсуждали. Семен, обсуждали ли мы с тобой, что будет в MVP? Нет, еще не обсуждали.

Ну, калькуляторы, мы калькуляторы делаем, вот, со, ну и если это какой-то поиск просто по нормативке, интеллектуальный, это, ну, как бы тоже в таком же виде, возможно, посчитать больничный еще как отдельная функция. А, слушай, кстати, можно я тебя сейчас еще отправлю в эту мьюзер-стори, которую Вадим делал, или это потом? Лови, я сейчас тебе, я, я, я сейчас тебе, я прям, я прям сейчас, прям сейчас, короче, отправлю сюда. А, блин, сейчас, сейчас, да, кайф. Вот, я сделал, смотрите, вот, кайф. Да, поехали. Да, я запрошу, короче, насколько плохо, что сейчас у нас, возможно, в записи у меня картинка статичная вдруг стала, но звук красава. Слово бота, и рассчитываем, что бот нам отдадут, что нам делать с человеком. Ну, вот, да, тут хочется подумать над, а, ну, да, короче, подумать над юзер-экспириенсом записывания. Скорее всего, это будет какая-то копипаста откуда-то из другой программы, где это все ведется, правильно? Ну, да, например. Вот, то есть, в целом, ой, я сейчас подумал над кейсом, это тоже, опять же, не MVP, но что-то, что в раннем пост-МВП работе можно рассмотреть. Если есть хоть какие-то стандарты в этих, ну, кстати, они же подают на печать, в итоге, вот это вот, простите, я плаваю в терминах. Короче, я как пациент пришел, меня обслужили и выслушали, сделали заключение, наверное, это называется. Короче, меня распечатывают бумажечку, на которой написано анамнез и рекомендации. Как эта бумажечка называется? Эпикриз. Вот, короче, как минимум почти все, я просто знаю, что в больницах у всех абсолютно разные системы для вот этого процесса. Но при этом на печать, в итоге, подается всегда одно и то же. Как будто бы прикольно уметь съедать вот эту PDF или что-то, обрабатывать и, ну, типа, дополнять нашим мнением. У врача уже что-то было, я понимаю, что для того, чтобы сгенерировать ответ для пациента, врачу нужна помощь в нашей работе. Но прикольно как-то попробовать выдергивать, короче, какой-то шаг интеграции с системами, в которых врачи уже работают. Называется медицинская информационная система, с медицинской информационной системой работать, значит. Да, но смотри, она не будет на ранних этапах точно какой-то узкой интеграции с какой-то конкретной системой. И я просто прикидываю о том, что может быть интеграция на уровне закинуть PDF по-быстрому о пациенте, чтобы не перепечатывать всю фигню. Ну, OCR, да, подобное. Это было бы прикольно. Я просто стараюсь подумать над инфу, потому что человеку перебивать бота всю инфу будет не супер удобно. Я прямо сейчас скину идею с OCR, которая была здесь. Ладно? Прямо сейчас. Ну, заготовку под OCR microservice у нас уже есть. Посмотри, пожалуйста. Короче, когда у нас часть доков в клиндеках отсутствовала в виде нормального, удобно читаемого текста, то были буквально PDF-ки, то есть сканы. Ну да. Быстро перебить в текст. Попробовали марки. Нормально работает. Я думаю, что его будет достаточно на старте. Если текст он в электронном виде, то он даже не пытается вжать ресурсы в OCR, ограничивается им. Человек скачал нормальную PDF-ку, а не скан. Я так полагаю, что в миссии там все-таки PDF-ка не слишком жирная. Это и проходить по нашим системам будет быстрее. Окей. Огонь, огонь. Вот. Вопрос. Мы хотим на старте демонстрировать OCR. Мне кажется, это прикольно. Не, не, я говорю это просто… Не очень жирно в плане подъема. То есть это не то, что какая-то азиатическая локация. Ну, просто тогда с низким приоритетом. То есть это не критично для запуска MVP, но если, получается, укладываетесь по времени, то почему бы и нет? Да, согласен. Едем дальше? Да. Я в целом прочитал, да. Окей. Я пока не читал дальше того, что вы читали. Да-да, конечно. Давай, прочитай, конечно. По-по-по. Так, сразу вопрос. Для этого достаточный клинрек или нужны еще какие-то источники знаний для этого пункта? Какого? Врач вне приема. Клинической рекомендации, да. И, в принципе, это в первую очередь оно. Но там нужно еще перечень. Надо у Вадима все это поспрашивать. Все это к нему. То есть он должен подготовить, откуда это брать. По каждому. Окей. То есть сейчас каких-то новых медиа мы тут не видим. Просто усложнен вариант предыдущего сценария, в котором нужно позаботиться о том, чтобы все точно соответствовало. Ну вот, я это вижу как раз. И еще вопрос. Бывает такое, что клинреки протухают, насколько я знаю. И что некоторые из них становятся не слишком достоверными. Насколько я знаю, Константин предлагал делать автообновление клинреков. Автопарсер прикрутить просто. И условно раз в неделю чекать хэши, пдфы или что-то подобное. Ну раз в неделю, потому что суперчасто они требуются. Я смотрел, они вроде обновляются не реже, чем раз в три года, но не чаще, чем раз в год. Мы хотим на своей стороне как-то еще дополнительно бализировать информацию с клинреками. Мы просто предполагаем, что истина в последней инстанции. Это истина в последней инстанции. Именно так и предполагаем, как я понял. Да, это канон медицины в России. Мы пока не рассматриваем зарубежные клинреки, рекомендации всяких медицинских обществ и так далее. Это более ебанутая задача на перспективу, да, но не прям завтра. Окей. Самый сложный сценарий Вадим обозначил тот, в котором он хочет видеть детализацию, как некоторый кук-кук, как мы проводим операцию, что нам для этого нужно, какие вещи и какие шаги. Еще чего остерегаться. Это тоже решается только регом клинреков. Оно есть в клинреках, либо в стандартах, надо почитать, спросить его, откуда это взять. Окей. Ладушки. Так, на старте мы хотим видеть все сценарии из тех, что обозначили. А сколько студентов вообще пока не вижу, если честно. Это не наши ЦА сейчас. Ну да, на них нельзя работать. Ну и насколько я понимаю, мы уже на старте хотим верификацию какую-то, что перед нами человек с дипломом. Или мы будем ботапускать вообще всех, кто узнает об этом? Не, хорошо бы верифицировать, потому что вообще как будто бы эти знания открытые. Сами клинреки, они же открытые. Но стрёмно, что люди могут начать типа самолечением заниматься. Сереж, смотри, изначально тут была верификация диплома на ручной, а уже на этапе MVP. Это нужно чисто для того, чтобы таргет был лучше. Во-первых, не просто таргет. Во-первых, возможность зарабатывать большое количество бабок и то, что там не только на таргетированной рекламе формы, которая недоступна для обычных юзеров. Потому что есть закон, который не дает нам рекламировать условно некоторые виды услуг и товаров людям без специализированного медицинского образования. Кроме этого, это аудитория для опросов и прочее. Простите, что за идея? Она выскочила и требует озвучки. Не в MVP, но дальше в развитии продукта. Можно сделать а-ля freemium. Короче, бот работает и отвечает как-то не глубоко. Без верификации диплома, но постоянно напоминает о том, что если верифицировать диплом, вы получите профессиональные рекомендации. Ну это просто мысль. Это точно не на сейчас. Даже записывать не надо. Мы записали уже на диктовку. Погнали дальше. Второй момент это юридический момент, который связан с тем, что как будто бы наличие диплома ответственность нашу не так и снижает. Не люди занимаются самолечением, а врач. Да, да, я это понял. ...принимает решение на основании опыта на свой страх и риск. Точно так же как он. Ну как бы так же на клинрек ссылается, просто здесь ему бот очень точно может сказать где что. Вот, и как будто бы... Да, мы потом запромтим бота, чтобы он всегда отвечал, что он своего мнения не имеет. Вот вы держите, решайте сами, что делать в данном случае. Юрист поможет с этим, тоже это обсуждали, скорее всего, завтра. Не, это как раз Костя поможет с этим, мы промто тюним, чтобы бот не высказывался о том, как в данном случае лечить пациента. Он только должен рассказать, что стандарты об этом думают. Окей. Мы хотим это на старт. С первого дня. Да. Верификацию диплома. Окей. В первый день мы хотим, чтобы это быстро обрабатывалось. Чтобы люди не сидели вообще на регистрации, пока там человек... Чуваки, давайте сделаем это в тупую... Прости, Сём, Сём, прости, пожалуйста. Давайте сделаем это прям в тупую, в тупую. Она у нас как бы существует формально. Мы предполагаем, что ранняя аудитория не содержит хитроумных скамеров, которые легко обойдут верификацию нашего диплома. Поэтому верифицировать, условно, через запиху чата GPT, в которую кидается фотография и спрашивается, это диплом медицинский или нет. Там, короче, перебиваю, мы сейчас для медики нормальную систему верификации делаем, но возможно она не понадобится. Настя, я тоже хочу... Я как раз про это и хотела спросить. Зачем два раза делать одну и ту же работу, если мы для медики уже настраиваем работу, ну, именно проверку верификации? Да. Но это... Мы можем просто... Это должно быть отдельным сервисом, который может подслуживать. Мы не можем. Окей, может быть, возьмем, как в этом было, в справочнике врача? Настя, когда скачивала приложение, там же, типа, не было задачи подтверждения. Так, что там было, не помнишь? В справочнике врача только калькуляторы были. Нет, но там же спрашивали специалисты медицинские и так далее. Ну да, там просто указываешь, где ты работаешь и галочку ставишь, что я принимаю на себя всю ответственность за то, что я ложные данные даю. Может быть, так и сделать и не париться на старте? Ну, это надо с юристом говорить. Смотри, смотри, галочка с ответственностью точно эффективнее работает, чем проверка диплома. Потому что проверка диплома не перекладывает ответственности, не фиксирует согласия. Хотя можно сказать, что если вы отправили свой диплом, вы принимаете на себя ответственность. Я просто рандомно накинул и не услышал никакой реакции, что на раннем этапе необязательно делать реальную учительную проверку. Но сам ритуал проверки сделать, короче, это театр безопасности. И просто спрашивать учителя диплома, это медицинский диплом, да, нет. А потом, естественно, делать нормальный процесс. Я про саму верификацию, что диплом это или не диплом. Я про то, что, возможно, галочки будут достаточные. Галочку, возможно, проще сделать, чем чат. Окей, окей.

что-то подобное. Смотри, как я это вижу, когда я говорю ChargePT, я имею в виду, что на нем нам легче проектировать MVP, тестировать и все такое. В Production ChargePT никак не может. Дело не в этом, мне кажется, просто галочку надо сделать. Просто у них самая развитая пиха, и разработчику легче всего работать с ChargePT и кодом с точки зрения использования современных течей LLM. Я хочу на это вложить. Давайте сделаем справочник у врача и все. Вот можно и то, и то. И галочку, и только не ChargePT условную, а сделать отдельного плита в телеге для специалистов. Взять какое-нибудь ответственное лицо от себя, Анастасию, еще кого-то, и там будет ему в телегу приходить диплом с двумя кнопками. Действительно диплом? Нет, он врет. Он будет нажимать, ответственный человек, на кнопку и подтверждать, что да, мне кажется, это диплом. Да, типа того. Типа да, нет. То есть ручка. В принципе, да, нагрузка. И в первый месяц я, например, вполне справлюсь. Ну да, я не думаю, что там будет миллиарды дипломов в день. Окей, все, вставляем ручку здесь. И я немного вперед задержал, извиняюсь, потому что что-то зацепилось с прошлой вкладки, как раз-таки по верификации. Вернемся чуть-чуть назад. Самое жесткое с точки зрения сопротивления Вадима, честно, сколько я помню, это то, что у нас должна быть все-таки какая-то людская валидация. То есть либо так, как она сейчас выделена на кусочке, текст жпт награвицинировал, либо так, как думали до этого, о том, что у нас есть некоторый пул вопросов и пул образцовых ответов. Это, я так понимаю, то, про что Константин делал форму фидбэка с лайком-дизлайком и подробным текстом, если что-то не так. Что оттуда можно взять залайканные вопросы, попробовать блабануть просто какой-нибудь классификатор, типа какой вопрос наиболее вероятно будет залайкан. Пара какого вопроса и ответа. И оценивать как раз-таки степь неподобия идеального вопроса и имущественного ответа модельки. Чтобы если мы собираемся что-то обновить, то сначала мы проверяем на некотором пуле, который мы можем проверять. Да, тут я демку включил, если понадобится посмотреть. Примерно такие метрики, но, как видно, особо никто не горит желанием оставлять рейтинг. А какая модель монетизации у вас будет? У врачей доступ бесплатный? Подписка сразу. А что дает подписка? Она запросы дает ограниченные, неограниченные? В понедельник Сережа Трошин пришлет планы по монетизации. Короче, есть тоже рандомная мысль, которую не обязательно вкручивать, но, возможно, ревьювинг ответов может давать пользователю некоторые токены запросов. То есть, если пользователь поработает на нас как оценщик, то он может получить какие-то блага. Но это отдельная тоже история. Надо будет перепроверять, иначе у нас может быть ситуация, что я ради токенов везде отмечу, что все подходит. Ты права. Поэтому любой вопрос должен быть отправлен нескольким людям одновременно. То есть, там должен быть консенсус, конечно. С автобаном того, кто проголосовал против. Ну, с пометкой тех, кто неверно оценивает. Это обычная ЕГЭСная история, что там проверяют изначально два эксперта, если они согласились, то третий. Ну, и вот. Я бы согласен, что у вас, так как это медицинская рекомендация, я бы делал, наверное, минимум три раза нужно отревьювать штуку, чтобы составить понятие, какое мне некоторое мнение. Но это тоже не MVP, но просто я подумал, что такой подход может иметь смысл. Это, помнишь, у нас был с тобой разгон по поводу врачей против ИИ? Да, да, да. Врачи против ИИ, да. По-моему, хорошая идея. Подумай. Мне кажется, это нужно реализовать здесь как раз. Ну, надо думать, какая мотивация. Мы сейчас думаем о том, что мы хотим сделать до того, как выкатим на публику. То есть, понятно, что этот шаг как публично поможет еще какую-то разметку собирать. Спасибо. Очень круто, очень удобно. Но вот до этого нам… Не MVP, точно. Я сразу говорю, не MVP. Это позже. Просто зафиксировать идею. А я хочу поговорить как раз о том, что нам нужно сделать к первому дню. Насколько я помню, 15 июля мы с ним спланировали. Нам нужен какой-то железобетонный набор, который мы можем использовать всегда для аппликации модели. Ну, не то, что всегда. Понятно, что со временем все равно мы его перерастем. Но на старте то, почему мы там сможем быстро оценить качество модели и проверить, что он удовлетворяет нас. Мы уже пытались запустить один раз. Насколько я помню, не очень успешно. Кость, там были какие-то подвижки по истории? Ну, я попробовал, как я говорил, мангинерить вопросов. 10 баксов, что у меня были на аккаунте DeepSeek и улетели достаточно быстро. Потому что клинрек, оно звучит как бы… Теоретически просто сделать кучу вопросов. Они должны быть достаточно полными. Я делал примерно так, что у нас 10 вопросов примерно на 10 страниц должно выходить. Проблема в том, что там страниц 40 тысяч или даже больше. Суммарно, по всем клинрекам. То есть это объемно, это, во-первых, сделать. Но даже разово это не проблема, это не так много денег. Но каждый раз гонять после каждой правки модель по всем этим вопросам, это будет много денег. Я не знаю, наверное, баксов 300 за раз прогнать. Так а зачем по всем гонять? По полному набору, да. Делай тест-фейс, да-да-да, сделай ограниченный набор и гоняй по нему, чтобы точность замерить. Это нужен качественный набор очень. Его, скорее всего, вручную надо будет сделать. Конечно. Окей, а есть представление, какого количества нам будет достаточно на старт? Условно, есть разные специализации врачей. Нам нужно хотя бы покрыть каждую из них. А вот каждую из них это будет тяжело. Я смотрел, вот есть тесты НМО, как раз что я тебе кидал. Непрерывное медицинское образование. И я скачал матрицу как раз по клинрекам, какие клинреки нужно пойти каждому врачу, чтобы их получить. Это НМО, но это другая история. Кстати, это можно интегрировать. Надо, кстати, вообще тоже подумать, как эту хрень добавить. Я думаю, ты не туда идешь. Я в целом говорю, что чтобы нам валидировать по всем вопросам, охватить все специализации, там все равно счет идет на десятки тысяч вопросов. Но это для чего это? Мы сейчас говорим про настройки, оценку качества нашего ответа? Да, да, да. И там не совсем корректно, потому что мы требуем от модели синтеза знаний. То есть там она должна выбрать, условно, из пяти вариантов ответа, варианты ответов. И хотя по факту она нашла эти ответы, указала в своем отчете, она может в конце выбрать не совсем то, просто потому что это тупо, дешево и условно. Короче, вот это хороший вопрос, к которому мне нужно сходить к Леше, который финансовый рак делает. Типа как оптимизировать тестирование, потому что для каждого MBD на огромную базу знаний перегенерировать, ну это пиздец, нельзя так жить. Ну да, вот по-хорошему, на самом деле, на мой взгляд, хватило бы взять 200-300 вопросов, и человек даже должен не столько четко описывать ответ идеальный, как я изначально думал. Ему достаточно написать несколько критериев, 5, 6, 10, в которых он, допустим, берем полиноз, потому что я этот вопрос уже сто раз задавал, и он, допустим, спрашивает, какие симптомы при хроническом лините там возникают. И он пишет свой золотой ответ, что проверить наличие следующих симптомов в ответе, и перечисляет там 5 симптомов. А потом мы уже другой ЛЛМкой сверяем ответ, который наш бот сделал, с указаниями эксперта того, что должно содержаться в ответе. То есть эксперту не обязательно написать ответ, ему нужно просто написать, что должно быть в ответе. И просто за счет того, что мы если полностью покрываем все критерии, значит, хорошо работает. Если покрываем часть – ну, тоже хорошо, смотря, какую часть покрываем. То есть прикол в том, что ему не нужно делать полноценный ответ, ему нужно просто написать под каждый вопрос какие-то точечные специализированные критерии, по которым можно оценить конкретно этот вопрос. И таких вопросов 100, даже 100, наверное, хватит, я думаю. И это будет не так дорого организироваться. Там, скорее всего, нужно будет чуть позже. То есть сначала сделать наивную имплементацию в блоках, так сказать, а потом просто уже тестировать, когда мы будем видеть, в каких случаях модель уходит от ожидаемых результатов. Собственно, в набор тестов включать, так скажем, загадки для моделей, то есть пытаться их запутать и смотреть, что они это запутывание продолжают успешно решать. И, кстати, вот еще насчет агентов отчасти. Почему я пока не использовал никакой схемы с разбиением под задач? И почему именно Flash используем? Потому что я хотел изначально использовать как раз китайские у нас, потому что мы потом можем их селфхостить в России локально, и данные никуда не утекают. Ну, ламу тоже можем, правда. Ну, ламу, не знаю, мне не нравится лама. Она сосет на бенчмарках в большинстве, на мой взгляд. Ты имеешь право на этот взгляд. Четвертое, и все они дерьмоволны. И на русском они очень плохо, на самом деле. Да, согласен. А вот какой-нибудь, типа, квен взять? Да, да. Он вполне влезет. И его использовать. Но ключевой момент, на мой взгляд, это лотенция ответа. То есть, типа, врач не будет писать в бота «лечение полиноза», а потом пять минут смотреть на пациента, пока бот ему ответит. Сейчас, сейчас, нагрузится. Да, да. Поэтому используется Flash, что он там генерирует по 200 токенов в секунду. И он это делает за один проход. То есть мы сразу получаем релевантную инфу, сразу на нее отвечаем. Это понятно. Нужно в личной части определить комфортное время ожидания для врача. Понятно, что там можно использовать многоэтапный при процессе к нейронками текста. Да нет, просто смотри, бро. Прости, пожалуйста. Прости, пожалуйста. Круто, что ты себе это представляешь. Эти оптимизации обязательно можно будет когда-нибудь проработать. Вначале, если проект перспективный, и вся моделька работает, и мы получаем хороший фидбэк от ранних юзеров, проблема решается просто мощным железом. Все. Просто берется дорогой серват. Ну как бы да, но мы в Гемении не захостим у себя. Нет, так мы не можем гугл использовать никак в продакшн. Да, я и говорил. Ну в смысле, по закону. Она как минимум закрытая, да, а во-вторых, она недоступна. Да-да, я про селфхост от Кейса. Селфхост от Кейса. Вам просто сам хост нужно будет апать до продакшн-грейда, до какого-то серьезного железа, чтобы токены отдавались быстренько. А вот квен, кстати, китайский и другие опенсорсные модели у меня не получилось использовать в бате нашем. По той причине, что провайдеры, ну я open router использую, они сейчас не предоставляют нужные мне настройки под этот. То есть у квена есть, например, два режима. Это syncing-мод, когда он размышляет, а есть без синкинга, когда он не размышляет. И по-хорошему бы сделать так, чтобы вызов инструмента для поиска чисто он делал без размышления, а на сам поисковую выдачу он отвечал уже с размышлением, чтобы более качественно сделать. Но это не получается сейчас сделать. Для этого нужно рвакометь. Понял тебя. Мое мнение такое, что R&D, когда бот проектируется, когда фичи делаются, и мы пытаемся просто реализовать фичу, нормально использовать Google, нормально использовать ChargePT. А потом, естественно, придется даунгрейдиться до открытых моделей, которые уже засталпочены. Если у нас дедлайн 15 июля, то получается где-то до конца июня можно спокойно работать на внешних опихах, а потом заниматься переездом на то, что можно реально в продакшн выкатить и грустить от того, что они немножко попели. Просто я объясню свой взгляд. Всегда вот эти коммерческие, которые по факту мы не можем использовать никак в модели, они отбережают open source на полгода. Но все равно гонка идет и к тому моменту. То есть мы выкатим, у нас будет ранняя версия через полгода. У нас будет open source модель, которая не уступает той, на которой мы изначально разрабатывали фичу по своему уровню интеллекта. Вот, я на заставочку просто делаю все. Ну, стоит надеяться. Не обязательно в самом начале иметь суперидеального бота. Нам нужно будет юзер-фидбэк собирать, улучшать. То есть сразу эта штука не должна магически исцелять людей. Главное, чтобы она в доке хорошо паршивая. Я вот не уверен, даже если мы гугл будем взять на разных стадиях проекта, кем нам это грозит. Мне кажется, особо ничем. Наоборот, мы даже соберем флешку из проекта. Извини, как раз флеша этого самого, его ответа. От Яндекса нет решений никаких? У Яндекса есть Яндекс.cloud. То есть они предоставляют хостинг опенсорственных моделей, и ты можешь их использовать. Слушай, у них, кажется, твоя модель тоже последняя, наконец, была не позорная. Артем, а можешь заметить, микрофон очень громко клавиатурой офигачит? Я просто на бесшумную перейти. На бесшумную клавиатуру? Да. Ладно. Скажи, если бесшумная. Я гонял на своем железе модельку их, которую они в Opensource выложили, лайтовскую. Говнище полное, если честно. Я не тестил Яндекс, мне не было вообще необходимости связывать с русскими моделями. Но я просто слышал, что последний закрытый большой Яндекс менее позорный, чем все предыдущие. Большой не знаю, я лайт-версию на 7 миллиардов параметров тестил. 7 миллиардов, они все в страты, слушай. Ну да, но она уступает оригинальной модели на английском языке. То есть они взяли квен китайский и они притрен ему переделали. И потом еще и тюн делали дополнительный, да. Классика. Но при этом она на русском получилась хуже, чем квен на английском. Ну, кстати, короче, да. Я думаю, что тут нахакается. Главное – основный функционал сделать. А вот эти хаки о том, как поставить модельки, как пожонглировать модельками так, чтобы это нам недорого обходилось в итоге в продакшене, это уже за рамками MVP. В MVP нужно протестировать, что сама идея продукта работает. А, еще есть момент вот такой, что у Яндекса цены какие-то просто неадекватнейшие. На модели я смотрел, это безумие какое-то. Понял, бывает, да. У Сбербанка тоже. Сбербанковская модель, ну, она не то чтобы плохая, она примерно как четвертая птичка на русском, но она стоит как о-четыре мини модель. Ну да, но они зарабатывают чисто на том, что никто из корпоратов в России не может пользоваться нормальными западными моделями. Четыре бакса стоит за лям токенов, но при этом она на 20 миллиардов параметров с тремя активными экспертами. Немного даже, я бы сказал. Ей цена, не знаю, 20 центов условных. Друзья, я прошу прощения, мне уже нужно отскакивать. Я хотел бы, Серег, скинь мне потом, пожалуйста, запись. Я тоже сам поиграю с транскрибацией и думаю, что она будет сильно от вашей отличаться, но типа поиграюсь. Вот. Большую часть мы покрыли. По документу этому, как будто бы, мое мнение сейчас вообще не особо важно. И самое, ну, типа, интересное для себя, как, ну, типа, в каком состоянии находится кодовая база, на каком этапе и так далее, я уже усвоил. Подумаю над этим, помедитирую и с Сережей обсужу. И там, если будет появляться в этом какой-то смысл, буду рад еще с вами пообщаться и, ну, короче, попомочь чем могу. Очень приятно познакомиться. Вы крутые. Все, спасибо. Спасибо, хорошего вечера. Пока-пока. Давайте.